{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8MmLTrlUT6fLH+hxWd+tf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rIDvaCutO4m",
        "outputId": "dc64fa11-75e0-4b2c-c1c2-e4354ab23cb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Total Loss: 112099083574338732032.00, w1: 2116477677.6813, w2: 146595.2151, b: 211589.3687\n",
            "Epoch 2, Total Loss: 307399525323251385942671936815155824820224.00, w1: 110831767063931371520.0000, w2: 7676620367168605.0000, b: 11080066206040862.0000\n",
            "Epoch 3, Total Loss: 842954867769009173002540774129984635010132170663530529611055104.00, w1: 5803831866687430586938771374080.0000, w2: 401994979379285964567347200.0000, b: 580220301770810599862697984.0000\n",
            "Epoch 4, Total Loss: 2311561504033722145018282301356798647146011477784122511171144794331129826823171473408.00, w1: 303924273961509602493059067181674698637312.0000, w2: 21050925500664812401304316217053413376.0000, b: 30383897742728787268539190292410007552.0000\n",
            "Epoch 5, Total Loss: 6338793203807500321985311362615615069148492723927193275881741612896848665793580349144174545740443108245504.00, w1: 15915341178853176230552369814482387968314492101591040.0000, w2: 1102355718767403199413555048992392076541611212800.0000, b: 1591087452857276745735123868048936834841213665280.0000\n",
            "Epoch 6, Total Loss: 17382318926198026702629805500986106686306433662210971955591371771058731733898902956396218177134750106170920595754968395284480000.00, w1: 833424989513599598202051932807964702692527448319216311972397056.0000, w2: 57726114258530869998681066729192322574589475566507089985536.0000, b: 83319108827822715981062522050960619747315143856878543437824.0000\n",
            "Epoch 7, Total Loss: 47666014892325852082119202591528450344540409807683796657055825919421195051662616196763664794973915987289877390354032533540417621034654352917034696704.00, w1: 43643249952357916508729054755048078568759157890876977821083341885357948928.0000, w2: 3022893799757278268208336330386809167290598745010666776329571646046208.0000, b: 4363100144744388904693156802375651815120444696130476854599766121644032.0000\n",
            "Epoch 8, Total Loss: 130710349140532301417612587304968528823542362490490874107610744178616390790078085022209446842169849050358181932249679497505471047886104874131893079006352408521388819742720.00, w1: 2285428551303245180447102133788426709586148047338323792598749410419766641717306982400.0000, w2: 158297280909750059840824390850212381518010315576634282415311161868041341303259136.0000, b: 228478714437612904308335817182718789239217504870348245193901658049344947158515712.0000\n",
            "Epoch 9, Total Loss: 358435573249287446318703973536359693722463154685122763887282073799373745344242209958191209625693269453835213207979265625193660125150327148961589419501396068913007080671250927141634716513337344.00, w1: 119679072223397981010952492805524000441927036208021745505002032412374510399736724093106665816064.0000, w2: 8289417625399994616906602871682891152714025932569537036877904603138913671927389310255366144.0000, b: 11964548421824633821240176694612131309590245068791697195302372510152472574578721405903306752.0000\n",
            "Epoch 10, Total Loss: 982906564134528932784652775173175083943277313825735867012525008365742888927983780377120479544731274811486943726786914020914562002787385828054043328719739689842362320198001657621734903081493342126212509295236349952.00, w1: 6267131090178119813557455018882372972218344095556348805035294618742109878763018652146252624360457319219200.0000, w2: 434084806595434912693034526966490079320004432512996362112005030649532614586505366994225380301259931648.0000, b: 626537221598706691419469686736035503102771573961530941872842212914950408796874712013104308822514597888.0000\n",
            "\n",
            "Predicted price for 70 sq m & 7 years old house: ₹30708943871063987736085319552742603683472153525553214312376940658732655356194606979155202288092316228156129280.000000 Lakhs\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Dataset: [Size (sq m), Age (years)]\n",
        "# ----------------------------\n",
        "X = np.array([\n",
        "    [50, 10],\n",
        "    [60, 5],\n",
        "    [80, 2],\n",
        "    [100, 1]\n",
        "])\n",
        "\n",
        "# Target Prices (in lakhs)\n",
        "y = np.array([150, 180, 260, 320])\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Feature Transformation: size^2 and log(age+1)\n",
        "# ----------------------------\n",
        "X_transformed = np.column_stack([\n",
        "    X[:, 0] ** 2,                 # size^2\n",
        "    np.log(X[:, 1] + 1)           # log(age + 1)\n",
        "])\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Initialize Parameters\n",
        "# ----------------------------\n",
        "w = [0.1,0.1]           # weights [w1, w2]\n",
        "b = 1           # bias\n",
        "lr = 0.00001                     # learning rate\n",
        "epochs = 10\n",
        "\n",
        "# ----------------------------\n",
        "# 4. SGD Training Loop\n",
        "# ----------------------------\n",
        "for epoch in range(1, epochs + 1):\n",
        "    total_loss = 0\n",
        "    for xi, target in zip(X_transformed, y):\n",
        "        # Forward pass\n",
        "        pred = np.dot(xi, w) + b\n",
        "        error = pred - target\n",
        "        total_loss += error ** 2\n",
        "\n",
        "        # Gradients\n",
        "        grad_w = 2 * error * xi\n",
        "        grad_b = 2 * error\n",
        "\n",
        "        # Parameter update (SGD step)\n",
        "        w -= lr * grad_w\n",
        "        b -= lr * grad_b\n",
        "\n",
        "    if epoch % 1 == 0 or epoch == 1:\n",
        "        print(f\"Epoch {epoch}, Total Loss: {total_loss:.2f}, w1: {w[0]:.4f}, w2: {w[1]:.4f}, b: {b:.4f}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Prediction on New House\n",
        "# ----------------------------\n",
        "new_size = 70\n",
        "new_age = 7\n",
        "\n",
        "# Transform input\n",
        "size_squared = new_size ** 2\n",
        "log_age = np.log(new_age + 1)\n",
        "new_input = np.array([size_squared, log_age])\n",
        "\n",
        "# Predict price\n",
        "predicted_price = np.dot(new_input, w) + b\n",
        "print(f\"\\nPredicted price for {new_size} sq m & {new_age} years old house: ₹{predicted_price:2f} Lakhs\")\n"
      ]
    }
  ]
}